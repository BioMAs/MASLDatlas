name: Deploy to Development Server

on:
  push:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force rebuild datasets'
        required: false
        default: false
        type: boolean

env:
  DEV_SERVER_PATH: /home/dev/masldatlas
  CONTAINER_NAME: masldatlas-dev

jobs:
  deploy-dev:
    name: Deploy to Development Server
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup SSH key
      uses: webfactory/ssh-agent@v0.8.0
      with:
        ssh-private-key: ${{ secrets.DEV_SERVER_SSH_KEY }}

    - name: Add server to known hosts
      run: |
        ssh-keyscan -H ${{ secrets.DEV_SERVER_HOST }} >> ~/.ssh/known_hosts

    - name: Prepare deployment script
      run: |
        cat > deploy-script.sh << 'EOF'
        #!/bin/bash
        set -e
        
        echo "üöÄ Starting MASLDatlas deployment on development server..."
        
        # Colors for output
        GREEN='\033[0;32m'
        YELLOW='\033[1;33m'
        RED='\033[0;31m'
        NC='\033[0m' # No Color
        
        log_info() { echo -e "${GREEN}[INFO]${NC} $1"; }
        log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
        log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
        
        # Configuration
        PROJECT_DIR="${DEV_SERVER_PATH}"
        BACKUP_DIR="${PROJECT_DIR}_backup_$(date +%Y%m%d_%H%M%S)"
        FORCE_REBUILD="${{ inputs.force_rebuild }}"
        
        log_info "üìÅ Target directory: $PROJECT_DIR"
        log_info "üíæ Backup directory: $BACKUP_DIR"
        
        # Create backup if directory exists
        if [ -d "$PROJECT_DIR" ]; then
          log_info "üì¶ Creating backup..."
          cp -r "$PROJECT_DIR" "$BACKUP_DIR"
          log_info "‚úÖ Backup created at $BACKUP_DIR"
        fi
        
        # Create or update project directory
        mkdir -p "$PROJECT_DIR"
        cd "$PROJECT_DIR"
        
        # Stop existing containers
        log_info "üõë Stopping existing containers..."
        docker-compose down || true
        docker stop ${CONTAINER_NAME} 2>/dev/null || true
        docker rm ${CONTAINER_NAME} 2>/dev/null || true
        
        # Clean up old images if force rebuild
        if [ "$FORCE_REBUILD" = "true" ]; then
          log_warn "üßπ Force rebuild requested - cleaning Docker images..."
          docker rmi masldatlas-app:latest 2>/dev/null || true
          docker system prune -f
        fi
        
        log_info "‚úÖ Container cleanup completed"
        EOF
        
        chmod +x deploy-script.sh

    - name: Deploy to development server
      run: |
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} 'bash -s' < deploy-script.sh

    - name: Copy project files
      run: |
        # Create temporary tarball excluding datasets and large files
        tar --exclude='datasets' \
            --exclude='*.h5ad' \
            --exclude='app_cache' \
            --exclude='tmp' \
            --exclude='.git' \
            --exclude='node_modules' \
            --exclude='*.log' \
            -czf masldatlas-deploy.tar.gz .
            
        # Transfer files
        scp masldatlas-deploy.tar.gz ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }}:${{ env.DEV_SERVER_PATH }}/
        
        # Extract on server
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} << 'EOF'
          cd ${{ env.DEV_SERVER_PATH }}
          
          echo "üì¶ Extracting project files..."
          tar -xzf masldatlas-deploy.tar.gz
          rm masldatlas-deploy.tar.gz
          
          echo "üîß Setting permissions..."
          chmod +x scripts/dataset-management/*.sh
          chmod +x scripts/deployment/*.sh
          chmod +x scripts/setup/*.sh
          
          echo "‚úÖ Files deployed successfully"
        EOF

    - name: Setup datasets and volumes
      run: |
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} << 'EOF'
          cd ${{ env.DEV_SERVER_PATH }}
          
          echo "üìä Setting up datasets..."
          
          # Create necessary directories
          mkdir -p datasets/{Human,Mouse,Zebrafish,Integrated}
          mkdir -p enrichment_sets
          mkdir -p app_cache
          mkdir -p logs
          
          # Check if datasets need to be downloaded
          DATASET_COUNT=$(find datasets -name "*.h5ad" | wc -l)
          
          if [ "$DATASET_COUNT" -lt 4 ] || [ "${{ inputs.force_rebuild }}" = "true" ]; then
            echo "‚¨áÔ∏è Downloading datasets..."
            ./scripts/dataset-management/manage_volume.sh download
          else
            echo "‚úÖ Datasets already present ($DATASET_COUNT files found)"
          fi
          
          # Verify dataset status
          ./scripts/dataset-management/manage_volume.sh status
        EOF

    - name: Build and start application
      run: |
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} << 'EOF'
          cd ${{ env.DEV_SERVER_PATH }}
          
          echo "üê≥ Building Docker image..."
          docker-compose build masldatlas
          
          echo "üöÄ Starting MASLDatlas application..."
          docker-compose up -d masldatlas
          
          echo "‚è≥ Waiting for application startup..."
          sleep 30
          
          # Health check
          echo "üè• Performing health check..."
          max_attempts=12
          attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            if curl -f http://localhost:3838/ >/dev/null 2>&1; then
              echo "‚úÖ Application is healthy and accessible!"
              break
            fi
            
            echo "üîÑ Attempt $attempt/$max_attempts - waiting for application..."
            sleep 10
            attempt=$((attempt + 1))
          done
          
          if [ $attempt -gt $max_attempts ]; then
            echo "‚ùå Health check failed - checking logs..."
            docker logs ${CONTAINER_NAME} --tail 50
            exit 1
          fi
          
          echo "üìä Deployment Status:"
          docker ps | grep masldatlas
          
          echo "üéâ Deployment completed successfully!"
          echo "üåê Application accessible at: http://$(hostname -I | awk '{print $1}'):3838"
        EOF

    - name: Cleanup and notification
      if: always()
      run: |
        # Cleanup local files
        rm -f masldatlas-deploy.tar.gz deploy-script.sh
        
        # Send deployment notification
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} << 'EOF'
          cd ${{ env.DEV_SERVER_PATH }}
          
          echo "üìù Deployment Summary:"
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo "üïê Deployment Time: $(date)"
          echo "üìÇ Project Path: ${{ env.DEV_SERVER_PATH }}"
          echo "üåø Branch: ${{ github.ref_name }}"
          echo "üìù Commit: ${{ github.sha }}"
          echo "üë§ Author: ${{ github.actor }}"
          
          # Container status
          echo ""
          echo "üê≥ Container Status:"
          docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep masldatlas || echo "No containers running"
          
          # Dataset status
          echo ""
          echo "üìä Dataset Status:"
          ./scripts/dataset-management/manage_volume.sh status | grep -E "(Dataset files|Directory size)"
          
          # Disk usage
          echo ""
          echo "üíæ Disk Usage:"
          du -sh ${{ env.DEV_SERVER_PATH }}
          
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        EOF

  # Job pour nettoyer les anciens d√©ploiements
  cleanup-old-deployments:
    name: Cleanup Old Deployments
    runs-on: ubuntu-latest
    needs: deploy-dev
    if: success()
    
    steps:
    - name: Setup SSH key
      uses: webfactory/ssh-agent@v0.8.0
      with:
        ssh-private-key: ${{ secrets.DEV_SERVER_SSH_KEY }}

    - name: Add server to known hosts
      run: |
        ssh-keyscan -H ${{ secrets.DEV_SERVER_HOST }} >> ~/.ssh/known_hosts

    - name: Cleanup old backups
      run: |
        ssh ${{ secrets.DEV_SERVER_USER }}@${{ secrets.DEV_SERVER_HOST }} << 'EOF'
          echo "üßπ Cleaning up old backups..."
          
          # Keep only the 5 most recent backups
          ls -dt /home/dev/masldatlas_backup_* 2>/dev/null | tail -n +6 | xargs rm -rf
          
          echo "üê≥ Cleaning up unused Docker resources..."
          docker system prune -f --filter "until=24h"
          
          echo "‚úÖ Cleanup completed"
        EOF
